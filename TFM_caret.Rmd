---
title: "Untitled"
description: |
  A new article created using the Distill format.
author:
  - name: Diego MP González
    url: 
    affiliation: Universidad Complutense de Madrid
    affiliation_url: 
date: "`r Sys.Date()`"
output: 
    distill::distill_article:
      fig_caption: false
      highlight: kate
      colorlinks: true
      code_folding: true
      toc: false 
      toc_depth: 3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.width = 9, fig.asp = 1, out.width = "50%",
                      message = FALSE, warning = FALSE,echo = TRUE,res = 400,cache = FALSE)#,
                      #cache.extra = 1)#reset cache globalmente

rm(list = ls())
cat("\f") #.BORRAR CONSOLA CTRL+L

##TOC START----
```

```{r library}

```

**Este documento RMarkdown contiene todo el código R utilizado para el desarrollo del TFM**

```{r seleccion, include=FALSE}

source("D:/source/funcion steprepetido binaria.R")
source("D:/source/cruzadas avnnet y log binaria.R")


listconti <- data |> 
              dplyr::select(-c(NOVIOLENCIA_P,violencia_p)) |> 
              colnames()
listclass<-c("")
vardep<- "violencia_p"

german2<-data[,c(listconti,vardep)]

means <-apply(german2[,listconti],2,mean,na.rm=TRUE)
sds<-sapply(german2[,listconti],sd,na.rm=TRUE)

germantris<-as.data.frame(scale(german2[,listconti], center = means, scale = sds))



```





```{r Depuración, include=FALSE}







#Recategorizar//por hacer






 #data <- 
  #  data |> mutate(across(.cols=c(CONTROL_P,VECON_P,VPSICO_P,
  #                                VFISICA_P,VSEXUAL_P,MIEDO_P,NOVIOLENCIA_P,violencia_p),as_factor))



#binarias

#resto

############################

#exploracion

 #transofrmar
 
 
#* Regresion logistica

#--
#* Red neuronal

#* XGBOOST

#* Ensamblado

#* series Temporales(SAS)

#objetivo clasificacion viogen

#*EXTRA*

#sistema de puntuacion

#evaluar heterogeneidad###


#objetivo pide ayuda||Cuerpos SE(<-transformacion||feature engineering)

#seleccion de casos(aquellas mujeres que han sufrido algun tipo de violencia)
#data_v <- raw_data |> 
#        filter(NOVIOLENCIA_P == 1) 

```









```{r Modelizacion, include=FALSE}
#* TREE

# Partición 80-20% de train y test
data_split <- initial_split(data, strata = NOVIOLENCIA_P, prop = 0.8)
data_train <- training(data_split)
data_test <- testing(data_split)

# Validación v-folds

data_cv <- vfold_cv(data = data_train, v = 3, repeats = 4, strata = NOVIOLENCIA_P)

#RECETA
data_rec_TREE <- recipe(data = data_train, NOVIOLENCIA_P ~ .)

#horneado
bake(data_rec_TREE  |>  prep(), new_data = NULL)


decision_tree_gini <-
  decision_tree(mode = "classification", tree_depth = tune("depth"),
                min_n = tune("min_n"), cost_complexity = tune("cost")) |> 
                set_engine("rpart") 

# Flujos de trabajo
data_tree_gini_wflow <-
  workflow() %>%
  add_recipe(data_rec_TREE) %>%
  add_model(decision_tree_gini)

#Grid
grid_tree <-
  expand_grid("depth" = c(4:8),
              "min_n" = c(4,8,10,15,20),
              "cost" = c(0.0001,0.0025,0.0030,0.0050,0.01))

#AJUSTE
#computación en paralelo

#Inicio paralelizacion
clusters <- detectCores() / 2  
make_cluster <- makeCluster(clusters,outfile = "")
registerDoParallel(make_cluster)
#clusterExport(make_cluster, "outlier_detection")
#showConnections()
#tic()
#--
data_fit_tree_gini <-
  data_tree_gini_wflow %>%
  tune_grid(resamples = data_cv,
            grid = grid_tree,
            control =
              control_grid(verbose = TRUE, allow_par = TRUE, save_pred = TRUE),
            metrics = metric_set(accuracy, sensitivity,
                               specificity, roc_auc))
#--
# finalizamos clusters
stopCluster(make_cluster)
registerDoSEQ()

# Métricas
metricas <- data_fit_tree_gini %>% collect_metrics()
#toc()

metricas %>%
  filter(.metric == "accuracy") %>% 
  arrange(desc(mean), std_err)


resultados <- data_fit_tree_gini %>% collect_metrics()
resultados %>%
  filter(.metric == "roc_auc") %>% 
  arrange(desc(mean), std_err)


resultados_tidy <-
  resultados %>% 
  pivot_longer(cols = c("cost", "depth", "min_n"),
               names_to = "parameter", values_to = "value")

media_resultados <-
  resultados_tidy %>%
  group_by(parameter, value) %>%
  summarise(mean = mean(mean),  .metric = .metric) %>%
  ungroup()

resultados_tidy

theme_set(theme_minimal())
ggplot(media_resultados,
       aes(x = value, y = mean)) +
  geom_line() +
  geom_point(size = 2) +
  facet_grid(.metric ~ parameter, scales = "free") +
  labs(x = "Parámetros", y = "Media (en todos los conjuntos de validación",
       title = "Resumen de las métricas en validación",
       caption = "Autor: Javier Álvarez Liébana")

theme_set(theme_minimal())
ggplot(media_resultados,
       aes(x = value, y = mean)) +
  geom_line() +
  geom_point(size = 2) +
  facet_grid(.metric ~ parameter, scales = "free") +
  labs(x = "Parámetros", y = "Media (en todos los conjuntos de validación",
       title = "Resumen de las métricas en validación",
       caption = "Autor: Javier Álvarez Liébana")


best_tree_gini_roc <-
  data_fit_tree_gini %>% select_best("roc_auc")
best_tree_gini_acc <-
  data_fit_tree_gini %>% select_best("accuracy")
best_tree_gini_roc_std <-
  data_fit_tree_gini %>% select_by_one_std_err("roc_auc", cost)
best_tree_gini_iris_acc_std <-
  data_fit_tree_gini %>% select_by_one_std_err("accuracy", cost)


final_wf <- 
  data_tree_gini_wflow %>% 
  finalize_workflow(best_tree_gini_roc)

final_tree_fit <- 
  final_wf %>%
  last_fit(data_split) 
final_tree_fit %>% collect_metrics()


# Predecir el conjunto test: devuelve la clase
predict(extract_workflow(final_tree_fit), data_test)

# Predecir las probabilidades (las necesitamos para la ROC)
predict(extract_workflow(final_tree_fit), data_test, type = "prob")



# Incluir predicciones en tabla
prob_test <- augment(extract_workflow(final_tree_fit), data_test)
# Matriz de confusión: etiqueta real vs etiqueta predicha
conf_mat_test <-
  prob_test %>%
  conf_mat(truth = NOVIOLENCIA_P, estimate = .pred_class)
conf_mat_test 
# todas las métricas en test
conf_mat_test %>% summary()


library(rpart.plot)

final_tree_fit %>%
  extract_fit_engine() %>%
  rpart.plot(roundint = FALSE,
             extra = 1)#extra = 1,3,4

library(vip)
fit_gini <-
  final_tree_fit %>% 
  extract_fit_engine()
fit_gini$variable.importance
vi(fit_gini)

fit_gini %>%
  vip() +
  labs(x = "Importancia", y = "Variables",
       title = "IMPORTANCIA DE VARIABLES",
       subtitle = "Con el paquete {vip}",
       caption =
         paste0("Autor: Diego Manuel Parra | ",
                "Datos: Macroencuesta 2019"))

```